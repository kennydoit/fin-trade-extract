name: Balance Sheet Bulk ETL

on:
  workflow_dispatch:
    inputs:
      processing_mode:
        description: 'Processing mode'
        required: false
        default: 'incremental'
        type: choice
        options:
          - incremental
          - full_refresh
          - universe
      universe_name:
        description: 'Universe name (for universe mode)'
        required: false
        default: 'fundamentals_eligible'
        type: string
      exchange_filter:
        description: 'Exchange filter (ALL, NASDAQ, NYSE, AMEX)'
        required: false
        default: 'ALL'
        type: choice
        options:
          - ALL
          - NASDAQ
          - NYSE
          - AMEX
      asset_type_filter:
        description: 'Asset type filter (ALL, Stock, ETF)'
        required: false
        default: 'Stock'
        type: choice
        options:
          - ALL
          - Stock
          - ETF
      batch_size:
        description: 'Batch size (symbols per batch)'
        required: false
        type: number
        default: 25
      max_batches:
        description: 'Maximum batches (0 = no limit)'
        required: false
        type: number
        default: 0
      max_symbols:
        description: 'Maximum symbols (0 = no limit, useful for testing)'
        required: false
        type: number
        default: 0
      failure_threshold:
        description: 'Failure threshold (0.0-1.0)'
        required: false
        type: number
        default: 0.5
  schedule:
    # Run monthly on the 15th at 10:00 AM UTC (fundamentals update less frequently)
    - cron: '0 10 15 * *'

jobs:
  balance-sheet-etl:
    runs-on: ubuntu-22.04
    permissions:
      id-token: write
      contents: read
    env:
      PYTHONUNBUFFERED: '1'
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r scripts/github_actions/requirements.txt

    - name: Configure AWS credentials (OIDC)
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: Bulk fetch balance sheet data with incremental ETL
      env:
        ALPHAVANTAGE_API_KEY: ${{ secrets.ALPHAVANTAGE_API_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
        S3_BUCKET: fin-trade-craft-landing
        S3_BALANCE_SHEET_PREFIX: balance_sheet/
        SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
        SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
        SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
        SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
        SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
        PROCESSING_MODE: ${{ inputs.processing_mode || 'incremental' }}
        UNIVERSE_NAME: ${{ inputs.universe_name || 'fundamentals_eligible' }}
        EXCHANGE_FILTER: ${{ inputs.exchange_filter || 'ALL' }}
        ASSET_TYPE_FILTER: ${{ inputs.asset_type_filter || 'Stock' }}
        BATCH_SIZE: ${{ inputs.batch_size || '25' }}
        MAX_BATCHES: ${{ inputs.max_batches }}
        MAX_SYMBOLS: ${{ inputs.max_symbols }}
        FAILURE_THRESHOLD: ${{ inputs.failure_threshold || '0.5' }}
        LOAD_DATE: ${{ github.run_number }}${{ github.run_attempt }}
      run: |
        echo "ğŸ“Š Starting incremental balance sheet ETL extraction..."
        echo "ğŸ”„ Processing mode: $PROCESSING_MODE"
        echo "ğŸŒ Universe: $UNIVERSE_NAME"
        echo "ğŸ¢ Exchange filter: $EXCHANGE_FILTER" 
        echo "ğŸ’¼ Asset type filter: $ASSET_TYPE_FILTER"
        echo "ğŸ“‹ Batch size: $BATCH_SIZE symbols per batch"
        if [ -n "$MAX_BATCHES" ] && [ "$MAX_BATCHES" != "0" ]; then
          echo "ğŸ›¡ï¸ Safety limit: Maximum $MAX_BATCHES batches"
        else
          echo "ğŸš€ Processing mode: All available batches"
        fi
        if [ -n "$MAX_SYMBOLS" ] && [ "$MAX_SYMBOLS" != "0" ]; then
          echo "ğŸ”’ Symbol limit: $MAX_SYMBOLS symbols (testing)"
        fi
        echo "âš ï¸ Failure threshold: $FAILURE_THRESHOLD"
        echo "ğŸ“… Load date: $LOAD_DATE"
        echo ""
        echo "ğŸ’¡ Note: Balance sheet data updates monthly/quarterly"
        echo "ğŸ“ˆ Expected coverage: ~4,000 fundamentals-eligible symbols"
        
        python scripts/github_actions/fetch_balance_sheet_bulk.py

    - name: Load bulk balance sheet data into Snowflake
      env:
        SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
        SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
        SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
        SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
        SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
      run: |
        echo "ğŸ—„ï¸ Loading bulk balance sheet data into Snowflake..."
        python scripts/github_actions/snowflake_run_sql_file.py snowflake/runbooks/load_balance_sheet_from_s3.sql

    - name: Upload processing results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: balance-sheet-results-${{ github.run_number }}
        path: /tmp/balance_sheet_results.json
        retention-days: 30

    - name: Summary Report
      if: always()
      run: |
        echo "ğŸ“Š BALANCE SHEET INCREMENTAL ETL SUMMARY"
        echo "======================================"
        echo "ğŸ”„ Processing Mode: $PROCESSING_MODE"
        echo "ğŸŒ Universe: $UNIVERSE_NAME"
        echo "ğŸ¢ Exchange Filter: $EXCHANGE_FILTER"
        echo "ğŸ’¼ Asset Type Filter: $ASSET_TYPE_FILTER"
        echo ""
        if [ -f /tmp/balance_sheet_results.json ]; then
          python -c "
        import json
        with open('/tmp/balance_sheet_results.json', 'r') as f:
            results = json.load(f)
        print(f'ğŸ“ˆ Total symbols processed: {results[\"total_symbols\"]}')
        print(f'âœ… Successful: {results[\"successful\"]}')
        print(f'âš ï¸ Skipped: {results[\"skipped\"]}') 
        print(f'âŒ Failed: {results[\"failed\"]}')
        print(f'ğŸŒ API calls made: {results[\"api_calls\"]}')
        print(f'â±ï¸ Duration: {results[\"duration_seconds\"]:.1f} seconds')
        
        total_processed = results['successful'] + results['failed']
        if total_processed > 0:
            success_rate = results['successful'] / total_processed * 100
            print(f'ğŸ“Š Success rate: {success_rate:.1f}%')
        
        if results['api_calls'] > 0:
            calls_per_minute = (results['api_calls'] / results['duration_seconds']) * 60
            print(f'ğŸ“ˆ API rate: {calls_per_minute:.1f} calls/minute')
        "
        else
          echo "âš ï¸ No results file found"
        fi
        echo ""
        echo "ğŸ’¡ Balance sheet data provides comprehensive financial position"
        echo "ğŸ“ˆ Use with income statement and cash flow for complete analysis"
        echo "ğŸ” Data includes assets, liabilities, and equity for fundamental analysis"