name: Balance Sheet Bulk ETL

on:
  workflow_dispatch:
    inputs:
      processing_mode:
        description: 'Processing mode'
        required: false
        default: 'incremental'
        type: choice
        options:
          - incremental
          - full_refresh
          - universe
      universe_name:
        description: 'Universe name (for universe mode)'
        required: false
        default: 'fundamentals_eligible'
        type: string
      exchange_filter:
        description: 'Exchange filter (ALL, NASDAQ, NYSE, AMEX)'
        required: false
        default: 'ALL'
        type: choice
        options:
          - ALL
          - NASDAQ
          - NYSE
          - AMEX
      asset_type_filter:
        description: 'Asset type filter (ALL, Stock, ETF)'
        required: false
        default: 'Stock'
        type: choice
        options:
          - ALL
          - Stock
          - ETF
      batch_size:
        description: 'Batch size (symbols per batch)'
        required: false
        type: number
        default: 25
      max_batches:
        description: 'Maximum batches (0 = no limit)'
        required: false
        type: number
        default: 0
      max_symbols:
        description: 'Maximum symbols (0 = no limit, useful for testing)'
        required: false
        type: number
        default: 0
      failure_threshold:
        description: 'Failure threshold (0.0-1.0)'
        required: false
        type: number
        default: 0.5
  schedule:
    # Run monthly on the 15th at 10:00 AM UTC (fundamentals update less frequently)
    - cron: '0 10 15 * *'

jobs:
  balance-sheet-etl:
    runs-on: ubuntu-22.04
    permissions:
      id-token: write
      contents: read
    env:
      PYTHONUNBUFFERED: '1'
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r scripts/github_actions/requirements.txt

    - name: Configure AWS credentials (OIDC)
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: Bulk fetch balance sheet data with incremental ETL
      env:
        ALPHAVANTAGE_API_KEY: ${{ secrets.ALPHAVANTAGE_API_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
        S3_BUCKET: fin-trade-craft-landing
        S3_BALANCE_SHEET_PREFIX: balance_sheet/
        SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
        SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
        SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
        SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
        SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
        PROCESSING_MODE: ${{ inputs.processing_mode || 'incremental' }}
        UNIVERSE_NAME: ${{ inputs.universe_name || 'fundamentals_eligible' }}
        EXCHANGE_FILTER: ${{ inputs.exchange_filter || 'ALL' }}
        ASSET_TYPE_FILTER: ${{ inputs.asset_type_filter || 'Stock' }}
        BATCH_SIZE: ${{ inputs.batch_size || '25' }}
        MAX_BATCHES: ${{ inputs.max_batches }}
        MAX_SYMBOLS: ${{ inputs.max_symbols }}
        FAILURE_THRESHOLD: ${{ inputs.failure_threshold || '0.5' }}
        LOAD_DATE: ${{ github.run_number }}${{ github.run_attempt }}
      run: |
        echo "📊 Starting incremental balance sheet ETL extraction..."
        echo "🔄 Processing mode: $PROCESSING_MODE"
        echo "🌐 Universe: $UNIVERSE_NAME"
        echo "🏢 Exchange filter: $EXCHANGE_FILTER" 
        echo "💼 Asset type filter: $ASSET_TYPE_FILTER"
        echo "📋 Batch size: $BATCH_SIZE symbols per batch"
        if [ -n "$MAX_BATCHES" ] && [ "$MAX_BATCHES" != "0" ]; then
          echo "🛡️ Safety limit: Maximum $MAX_BATCHES batches"
        else
          echo "🚀 Processing mode: All available batches"
        fi
        if [ -n "$MAX_SYMBOLS" ] && [ "$MAX_SYMBOLS" != "0" ]; then
          echo "🔒 Symbol limit: $MAX_SYMBOLS symbols (testing)"
        fi
        echo "⚠️ Failure threshold: $FAILURE_THRESHOLD"
        echo "📅 Load date: $LOAD_DATE"
        echo ""
        echo "💡 Note: Balance sheet data updates monthly/quarterly"
        echo "📈 Expected coverage: ~4,000 fundamentals-eligible symbols"
        
        python scripts/github_actions/fetch_balance_sheet_bulk.py

    - name: Load bulk balance sheet data into Snowflake
      env:
        SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
        SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
        SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
        SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
        SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
      run: |
        echo "🗄️ Loading bulk balance sheet data into Snowflake..."
        python scripts/github_actions/snowflake_run_sql_file.py snowflake/runbooks/load_balance_sheet_from_s3.sql

    - name: Upload processing results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: balance-sheet-results-${{ github.run_number }}
        path: /tmp/balance_sheet_results.json
        retention-days: 30

    - name: Summary Report
      if: always()
      run: |
        echo "📊 BALANCE SHEET INCREMENTAL ETL SUMMARY"
        echo "======================================"
        echo "🔄 Processing Mode: $PROCESSING_MODE"
        echo "🌐 Universe: $UNIVERSE_NAME"
        echo "🏢 Exchange Filter: $EXCHANGE_FILTER"
        echo "💼 Asset Type Filter: $ASSET_TYPE_FILTER"
        echo ""
        if [ -f /tmp/balance_sheet_results.json ]; then
          python -c "
        import json
        with open('/tmp/balance_sheet_results.json', 'r') as f:
            results = json.load(f)
        print(f'📈 Total symbols processed: {results[\"total_symbols\"]}')
        print(f'✅ Successful: {results[\"successful\"]}')
        print(f'⚠️ Skipped: {results[\"skipped\"]}') 
        print(f'❌ Failed: {results[\"failed\"]}')
        print(f'🌐 API calls made: {results[\"api_calls\"]}')
        print(f'⏱️ Duration: {results[\"duration_seconds\"]:.1f} seconds')
        
        total_processed = results['successful'] + results['failed']
        if total_processed > 0:
            success_rate = results['successful'] / total_processed * 100
            print(f'📊 Success rate: {success_rate:.1f}%')
        
        if results['api_calls'] > 0:
            calls_per_minute = (results['api_calls'] / results['duration_seconds']) * 60
            print(f'📈 API rate: {calls_per_minute:.1f} calls/minute')
        "
        else
          echo "⚠️ No results file found"
        fi
        echo ""
        echo "💡 Balance sheet data provides comprehensive financial position"
        echo "📈 Use with income statement and cash flow for complete analysis"
        echo "🔍 Data includes assets, liabilities, and equity for fundamental analysis"