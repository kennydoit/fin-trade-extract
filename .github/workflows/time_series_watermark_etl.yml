name: Time Series ETL - Watermark Based
on:
  workflow_dispatch:
    inputs:
      exchange_filter:
        description: 'Exchange to process (NYSE, NASDAQ, AMEX, or leave blank for all)'
        required: false
        default: ''
        type: string
      max_symbols:
        description: 'Maximum number of symbols to process (blank = all eligible symbols)'
        required: false
        type: number
      skip_recent_hours:
        description: 'Skip symbols processed within this many hours (blank = re-process all)'
        required: false
        type: number
      batch_size:
        description: 'Number of symbols to process per batch'
        required: false
        default: 50
        type: number

jobs:
  etl:
    permissions:
      id-token: write
      contents: read
    runs-on: ubuntu-latest
    steps:
      - name: Decode Snowflake private key
        run: echo "${{ secrets.SNOWFLAKE_PRIVATE_KEY_DER_B64 }}" | base64 -d > snowflake_rsa_key.der

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install boto3 requests snowflake-connector-python

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ secrets.AWS_REGION }}
          role-duration-seconds: 43200

      - name: Fetch time series data using watermarks
        env:
          ALPHAVANTAGE_API_KEY: ${{ secrets.ALPHAVANTAGE_API_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          S3_BUCKET: fin-trade-craft-landing
          S3_TIME_SERIES_PREFIX: time_series/
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
          EXCHANGE_FILTER: ${{ inputs.exchange_filter }}
          MAX_SYMBOLS: ${{ inputs.max_symbols }}
          SKIP_RECENT_HOURS: ${{ inputs.skip_recent_hours }}
          BATCH_SIZE: ${{ inputs.batch_size }}
          CONSECUTIVE_FAILURE_THRESHOLD: ${{ inputs.consecutive_failure_threshold }}
        run: |
          echo "ğŸš€ Starting watermark-based time series ETL..."
          if [ -n "$EXCHANGE_FILTER" ]; then
            echo "ğŸ¢ Exchange filter: $EXCHANGE_FILTER"
          else
            echo "ğŸŒ Processing: All exchanges"
          fi
          if [ -n "$MAX_SYMBOLS" ]; then
            echo "ğŸ”’ Symbol limit: $MAX_SYMBOLS symbols (testing mode)"
          else
            echo "ğŸ“Š Processing: All eligible symbols from watermarks"
          fi
          if [ -n "$SKIP_RECENT_HOURS" ]; then
            echo "â­ï¸  Skip recent: Symbols processed within $SKIP_RECENT_HOURS hours will be skipped"
          else
            echo "ğŸ”„ Re-process: All eligible symbols will be processed"
          fi
          echo "ğŸ“‹ Batch size: $BATCH_SIZE symbols"
          echo ""
          echo "ğŸ“ Time Series Logic:"
          echo "  - Only active common stocks (ASSET_TYPE='Stock' AND STATUS='Active')"
          echo "  - Staleness check: Only fetch if last update > 1 day ago"
          echo "  - Update watermarks with last update timestamp"
          echo ""
          echo "Running Time Series ETL fetch script..."
          python scripts/etl/fetch_time_series_watermark.py

      - name: Load time series data into Snowflake
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
        run: |
          echo "ğŸ—„ï¸ Loading time series data into Snowflake..."
          python scripts/github_actions/snowflake_run_sql_file.py snowflake/runbooks/load_time_series_from_s3.sql

      - name: Clean up private key
        run: rm -f snowflake_rsa_key.der

      - name: Upload processing results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: watermark-etl-results-${{ github.run_number }}
          path: /tmp/watermark_etl_results.json
          retention-days: 30

      - name: Summary Report
        if: always()
        run: |
          echo "ğŸ“Š WATERMARK-BASED ETL PROCESSING SUMMARY"
          echo "=========================================="
          if [ -n "$EXCHANGE_FILTER" ]; then
            echo "ğŸ¢ Exchange: $EXCHANGE_FILTER"
          else
            echo "ğŸŒ Exchange: All"
          fi
          echo ""
          if [ -f /tmp/watermark_etl_results.json ]; then
            python -c "
          import json
          with open('/tmp/watermark_etl_results.json', 'r') as f:
              results = json.load(f)
          print(f'ğŸ“ˆ Total symbols processed: {results[\"total_symbols\"]}')
          print(f'âœ… Successful: {results[\"successful\"]} ({results[\"successful\"]/results[\"total_symbols\"]*100:.1f}%)')  
          print(f'âŒ Failed: {results[\"failed\"]}')
          print(f'â±ï¸  Duration: {results[\"duration_minutes\"]:.1f} minutes')
          # Show mode breakdown
          full_mode = sum(1 for d in results['details'] if d.get('mode') == 'full' and d.get('status') == 'success')
          compact_mode = sum(1 for d in results['details'] if d.get('mode') == 'compact' and d.get('status') == 'success')
          print(f'')
          print(f'Processing Mode Breakdown:')
          print(f'  ğŸ”„ Full refresh: {full_mode} symbols')
          print(f'  âš¡ Compact update: {compact_mode} symbols')
          # Calculate efficiency
          if results['total_symbols'] > 0 and results['duration_minutes'] > 0:
              efficiency = results['successful'] / results['duration_minutes']
              print(f'')
              print(f'âš¡ Processing efficiency: {efficiency:.1f} symbols/minute')
          print(f'')
          print(f'âœ… Watermarks updated for {results[\"successful\"]} symbols')
          print(f'   - FIRST_FISCAL_DATE set (if NULL)')
          print(f'   - LAST_FISCAL_DATE updated to latest data')
          print(f'   - LAST_SUCCESSFUL_RUN = current timestamp')
          print(f'   - CONSECUTIVE_FAILURES reset to 0')
          # Show delisted symbols marked
          if results.get('delisted_marked', 0) > 0:
              print(f'')
              print(f'ğŸ”’ Delisted symbols marked as API_ELIGIBLE=\"DEL\": {results[\"delisted_marked\"]}')
              print(f'   (Symbols with DELISTING_DATE that have been successfully extracted)')
          "
          else
            echo "âŒ No results file found - check logs for errors"
          fi
