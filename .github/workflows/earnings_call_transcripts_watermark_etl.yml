name: Earnings Call Transcripts ETL - Watermark Based

on:
  workflow_dispatch:
    inputs:
      exchange_filter:
        description: 'Exchange to process (NYSE, NASDAQ, or leave blank for all)'
        required: false
        type: choice
        options:
          - NYSE
          - NASDAQ
          - AMEX
        default: ''
      max_symbols:
        description: 'Maximum number of symbols to process (blank = all eligible symbols)'
        required: false
        type: number
      batch_size:
        description: 'Number of symbols to process per batch'
        required: false
        type: number
        default: 50
  schedule:
    # Run weekly on Sunday at 6 AM UTC (transcripts update less frequently)
    - cron: '0 6 * * 0'



jobs:
  watermark-earnings-call-transcripts-etl:
    runs-on: ubuntu-22.04
    timeout-minutes: 360  # 6 hours max
    permissions:
      id-token: write
      contents: read
    env:
      PYTHONUNBUFFERED: '1'
      AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Decode Snowflake private key
        run: echo "${{ secrets.SNOWFLAKE_PRIVATE_KEY_DER_B64 }}" | base64 -d > snowflake_rsa_key.der
        working-directory: ${{ github.workspace }}
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install boto3 requests snowflake-connector-python pandas
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ secrets.AWS_REGION }}
      - name: Fetch earnings call transcript data using watermarks
        working-directory: ${{ github.workspace }}
        env:
          ALPHAVANTAGE_API_KEY: ${{ secrets.ALPHAVANTAGE_API_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          S3_BUCKET: fin-trade-craft-landing
          S3_EARNINGS_CALL_TRANSCRIPT_PREFIX: earnings_call_transcripts/
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
          EXCHANGE_FILTER: ${{ inputs.exchange_filter }}
          MAX_SYMBOLS: ${{ inputs.max_symbols }}
          BATCH_SIZE: ${{ inputs.batch_size || '50' }}
        run: |
          echo "üöÄ Starting watermark-based earnings call transcript ETL..."
          if [ -n "$EXCHANGE_FILTER" ]; then
            echo "üè¢ Exchange filter: $EXCHANGE_FILTER"
          else
            echo "üåê Processing: All exchanges"
          fi
          if [ -n "$MAX_SYMBOLS" ]; then
            echo "üîí Symbol limit: $MAX_SYMBOLS symbols (testing mode)"
          else
            echo "üìä Processing: All eligible symbols from watermarks"
          fi
          if [ -n "$SKIP_RECENT_HOURS" ]; then
            echo "‚è≠Ô∏è  Skip recent: Symbols processed within $SKIP_RECENT_HOURS hours will be skipped"
          else
            echo "üîÑ Re-process: All eligible symbols will be processed"
          fi
          echo "üìã Batch size: $BATCH_SIZE symbols"
          echo ""
          echo "üìç Earnings Call Transcript Logic:"
          echo "  - Only active common stocks (ASSET_TYPE='Stock' AND STATUS='Active')"
          echo "  - One API call per symbol per quarter (2010 Q1 onward, or first full quarter after IPO)"
          echo "  - Update watermarks with transcript date range"
          echo "  - Mark API_ELIGIBLE='SUS' if no data for all quarters"
          echo ""


      - name: Load earnings call transcript data into Snowflake
        working-directory: ${{ github.workspace }}
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
        run: |
          echo "üóÑÔ∏è Loading earnings call transcript data into Snowflake..."
          python scripts/github_actions/snowflake_run_sql_file.py snowflake/runbooks/load_earnings_call_transcripts_from_s3.sql

      - name: Clean up private key
        run: rm -f snowflake_rsa_key.der
        working-directory: ${{ github.workspace }}

      - name: Upload processing results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: watermark-etl-results-${{ github.run_number }}
          path: /tmp/watermark_etl_results.json
          retention-days: 30

      - name: Summary Report
        if: always()
        run: |
          echo "üìä WATERMARK-BASED ETL PROCESSING SUMMARY"
          echo "=========================================="
          if [ -n "${{ inputs.exchange_filter }}" ]; then
            echo "üè¢ Exchange: ${{ inputs.exchange_filter }}"
          else
            echo "üåê Exchange: All"
          fi
          echo ""
          if [ -f /tmp/watermark_etl_results.json ]; then
            python -c "import json; f=open('/tmp/watermark_etl_results.json'); results=json.load(f); print(f'üìà Total symbols processed: {results["total_symbols"]}'); print(f'‚úÖ Successful: {results["successful"]} ({results["successful"]/results["total_symbols"]*100:.1f}%)'); print(f'‚ùå Failed: {results["failed"]}'); print(f'‚è±Ô∏è  Duration: {results["duration_minutes"]:.1f} minutes'); efficiency=results['successful']/results['duration_minutes'] if results['total_symbols']>0 and results['duration_minutes']>0 else None; print(f'‚ö° Processing efficiency: {efficiency:.1f} symbols/minute' if efficiency else ''); print(f'‚úÖ Watermarks updated for {results["successful"]} symbols'); print(f'   - FIRST_FISCAL_DATE set (if NULL)'); print(f'   - LAST_FISCAL_DATE updated to latest data'); print(f'   - LAST_SUCCESSFUL_RUN = current timestamp'); print(f'   - CONSECUTIVE_FAILURES reset to 0'); print(f'üîí Symbols marked as API_ELIGIBLE="SUS": {results["suspended_marked"]}' if results.get('suspended_marked',0)>0 else '')"
          else
            echo "‚ùå No results file found - check logs for errors"
          fi
          run: |
