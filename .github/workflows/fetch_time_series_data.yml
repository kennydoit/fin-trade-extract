name: Time Series Daily Adjusted ETL

on:
  workflow_dispatch:
    inputs:
      symbol:
        description: 'Stock symbol to fetch (e.g., AAPL, MSFT, GOOGL)'
        required: true
        type: string
        default: 'AAPL'
  schedule:
    # Run daily at 7 PM EST (after market close) for major symbols
    - cron: '0 23 * * 1-5'  # Monday-Friday at 11 PM UTC

jobs:
  time-series-etl:
    runs-on: ubuntu-22.04
    permissions:
      id-token: write
      contents: read
    env:
      PYTHONUNBUFFERED: '1'
    
    strategy:
      matrix:
        # Default symbols for scheduled runs, or use input symbol for manual runs
        symbol: ${{ github.event_name == 'workflow_dispatch' && fromJson(format('["{0}"]', github.event.inputs.symbol)) || fromJson('["AAPL", "MSFT", "GOOGL", "AMZN", "TSLA"]') }}
      fail-fast: false  # Continue processing other symbols if one fails
      max-parallel: 2   # Limit parallel jobs to respect API rate limits
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r scripts/github_actions/requirements.txt

    - name: Configure AWS credentials (OIDC)
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: Fetch time series data and upload to S3
      env:
        ALPHAVANTAGE_API_KEY: ${{ secrets.ALPHAVANTAGE_API_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
        S3_BUCKET: fin-trade-craft-landing
        S3_TIME_SERIES_PREFIX: time_series_daily_adjusted/
        SYMBOL: ${{ matrix.symbol }}
      run: |
        python scripts/github_actions/fetch_time_series_to_s3.py

    - name: Load time series data into Snowflake
      env:
        SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
        SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
        SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
        SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
        SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
        SYMBOL: ${{ matrix.symbol }}
      run: |
        # Create a temporary SQL file with variables substituted
        TODAY=$(date +%Y%m%d)
        sed -e "s/SET LOAD_DATE = '20251003';/SET LOAD_DATE = '$TODAY';/" \
            -e "s/SET SYMBOL = 'AAPL';/SET SYMBOL = '${{ matrix.symbol }}';/" \
            snowflake/runbooks/load_time_series_from_s3.sql > temp_load_script.sql
        
        # Run the SQL script
        python scripts/github_actions/snowflake_run_sql_file.py temp_load_script.sql
        
        # Clean up temp file
        rm temp_load_script.sql

